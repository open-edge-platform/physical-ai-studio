# Copyright (C) 2025-2026 Intel Corporation
# SPDX-License-Identifier: Apache-2.0


# ============================================================================ #
# BUILD SYSTEM CONFIGURATION                                                   #
# ============================================================================ #
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

# ---------------------------------------------------------------------------- #
# HATCH CONFIGURATION                                                          #
# ---------------------------------------------------------------------------- #
[tool.hatch.version]
path = "src/getiaction/__init__.py"

[tool.hatch.build.targets.wheel]
packages = ["src/getiaction"]

# ============================================================================ #
# PROJECT CONFIGURATION                                                        #
# ============================================================================ #
[project]
name = "getiaction"
dynamic = ["version"]
requires-python = ">=3.12"
authors = [{ name = "Intel - Open Edge Platform" }]
description = "An end-to-end training/inference framework for imitation learning of robot manipulation tasks."
readme = "README.md"
license = { file = "LICENSE" }
classifiers = [
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3.12",
]

# ---------------------------------------------------------------------------- #
# DEPENDENCIES                                                                 #
# ---------------------------------------------------------------------------- #

# --- Core --- #
# Core dependencies - lightweight, no torch required
# These are the minimum dependencies for using the inference API
dependencies = ["numpy>=1.24", "pyyaml>=6.0", "pillow>=10.0.0"]

# ---------------------------------------------------------------------------- #
# OPTIONAL DEPENDENCIES                                                        #
# ---------------------------------------------------------------------------- #
[project.optional-dependencies]


# --- PyTorch Ecosystem --- #
# Required for training and torch-based inference
torch = ["lightning>=2.0", "lightning-utilities"]

# Full training stack (~2.5GB+)
# Includes PyTorch, Lightning, LeRobot, and training utilities
train = [
    "getiaction[torch]",
    "lerobot>=0.4.1",
    "gymnasium>=0.29.1",
    "gym-pusht>=0.1.5",
    "pymunk>=6.6.0,<7.0.0",
    "onnx",
    "jsonargparse[signatures]>=4.27.0",
    "pydantic",
]

# --- PyTorch Hardware Backends --- #
# Mutually exclusive - install ONE based on your hardware
# Usage: pip install getiaction[cpu] or getiaction[cu128] or getiaction[xpu]
cpu = [
    "torch<2.11",
    "torchvision<=0.26.0",
]
cu128 = [
    "torch>=2.4.0,<=2.8.0",
    "torchvision>=0.19.0",
]
xpu = [
    "torch<2.11",
    "torchvision<=0.26.0",
    "pytorch-triton-xpu ; sys_platform == 'linux' or sys_platform == 'win32'",
]

# --- VLA Policy Dependencies --- #
# Heavy models with specific requirements
# Install with: pip install getiaction[pi0]

# Physical Intelligence Pi0/Pi0.5 foundation model
# Requires PaliGemma backbone + Gemma action expert
# Supports LoRA fine-tuning for efficient adaptation
pi0 = [
    "getiaction[train]",
    "transformers>=4.54.0,<5.0.0",
    "peft>=0.13.0,<1.0.0",
    "safetensors>=0.4.3,<1.0.0",
]

# NVIDIA GR00T-N1 foundation model
# Requires ~24GB+ GPU memory for training, supports LoRA fine-tuning
# Note: transformers>=4.54.0 required for _prepare_image_like_inputs fix
groot = [
    "getiaction[train]",
    "transformers>=4.54.0,<5.0.0",
    "peft>=0.13.0,<1.0.0",
    "dm-tree>=0.1.8,<1.0.0",
    "timm>=1.0.0,<1.1.0",
    "safetensors>=0.4.3,<1.0.0",
    "decord>=0.6.0,<1.0.0; (platform_machine == 'AMD64' or platform_machine == 'x86_64')",
    "ninja>=1.11.1,<2.0.0",
    "flash-attn>=2.5.9,<3.0.0; sys_platform != 'darwin'",
]

# SmolVLA foundation model
smolvla = [
    "getiaction[train]",
    "transformers>=4.53.0,<5.0.0",
    "num2words>=0.5.14,<0.6.0",
    "safetensors>=0.4.3,<1.0.0",
]

# --- Simulation & Evaluation --- #
# LIBERO simulation environment
libero = [
    "hf-libero>=0.1.3,<0.2.0",
]

# --- Inference Backends --- #
# Install based on your deployment target

# ONNX Runtime backend (~50MB)
# Best for: Cross-platform deployment, CPU/GPU inference
onnx = ["onnxruntime>=1.16"]

# OpenVINO backend (~100MB)
# Best for: Intel hardware (CPU, GPU, NPU), edge deployment
openvino = ["openvino>=2025.0"]

# --- Testing & Development --- #
tests = [
    "httpx",
    "pytest",
    "pytest-mock",
    "pytest-examples>=0.0.13",
    "mypy",
]

# Development dependencies (includes everything)
dev = ["getiaction[full]", "getiaction[tests]", "ruff>=0.1"]

# --- Convenience Bundles --- #

# Inference bundle: Core + common inference backends
inference = ["getiaction[onnx]", "getiaction[openvino]"]

# Full installation: Everything
full = [
    "getiaction[train]",
    "getiaction[inference]",
    "getiaction[pi0]",
    "getiaction[groot]",
    "getiaction[smolvla]",
    "getiaction[libero]",
]

# Legacy "all" alias for backward compatibility
all = ["getiaction[full]"]

# ---------------------------------------------------------------------------- #
# SCRIPTS CONFIGURATION                                                        #
# ---------------------------------------------------------------------------- #
[project.scripts]
getiaction = "getiaction.cli:cli"

# ---------------------------------------------------------------------------- #
# PROJECT URLS                                                                 #
# ---------------------------------------------------------------------------- #
[project.urls]
Homepage = "https://github.com/open-edge-platform/geti-action"
Documentation = "https://github.com/open-edge-platform/geti-action/blob/main/README.md"
Repository = "https://github.com/open-edge-platform/geti-action.git"


# ============================================================================ #
# UV CONFIGURATION                                                             #
# ============================================================================ #
# flash-attn requires torch during build but doesn't declare it as a build dependency
[tool.uv]
extra-build-dependencies = { flash-attn = ["torch"] }

conflicts = [
    [
        { extra = "cpu" },
        { extra = "cu128" },
        { extra = "xpu" },
    ],
]

# PyTorch index configuration
[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name = "pytorch-xpu"
url = "https://download.pytorch.org/whl/xpu"
explicit = true

# PyTorch sources configuration
[tool.uv.sources]
torch = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-cu128", extra = "cu128" },
    { index = "pytorch-xpu", extra = "xpu" },
]
torchvision = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-cu128", extra = "cu128" },
    { index = "pytorch-xpu", extra = "xpu" },
]

pytorch-triton-xpu = [
    { index = "pytorch-xpu", extra = "xpu" },
]


# ============================================================================ #
# MYPY CONFIGURATION                                                           #
# ============================================================================ #
# Inherits from root pyproject.toml, add library-specific overrides here
[tool.mypy]
ignore_missing_imports = true
show_error_codes = true


# ============================================================================ #
# RUFF CONFIGURATION                                                           #
# ============================================================================ #
[tool.ruff]
# Extend shared configuration from root
extend = "../pyproject.toml"

# Library-specific source directories
src = ["src", "tests"]

# Library-specific excludes (in addition to root excludes)
extend-exclude = [
    "docs",
    "examples",
    "tests",
    "notebooks", # Jupyter notebooks have different style requirements
]

# ---------------------------------------------------------------------------- #
# LINT CONFIGURATION                                                           #
# ---------------------------------------------------------------------------- #
[tool.ruff.lint]
# Library uses ALL rules from root config
# Add any library-specific ignores here if needed
ignore = []

# --- Ignores --- #
[tool.ruff.lint.per-file-ignores]
# Inference module: private helper functions use concise one-liner docstrings
# DOC201 (missing Returns) and DOC501 (missing Raises) are intentionally skipped
# for private methods to keep code concise - the behavior is clear from context
"src/getiaction/inference/adapters/__init__.py" = ["DOC201", "DOC501"]
"src/getiaction/inference/model.py" = ["DOC201", "DOC501"]


# ============================================================================ #
# BANDIT CONFIGURATION                                                         #
# ============================================================================ #
[tool.bandit]
skips = ["B101"]
exclude_dirs = ["tests"]


# ============================================================================ #
# PYTEST CONFIGURATION                                                         #
# ============================================================================ #
[tool.pytest.ini_options]
addopts = ["--strict-markers", "--strict-config", "--showlocals", "-ra"]
testpaths = "tests"
pythonpath = "src"
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "requires_download: marks tests that require downloading external datasets",
    "integration: marks tests as integration tests",
]


# ============================================================================ #
# COVERAGE CONFIGURATION                                                       #
# ============================================================================ #
[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if TYPE_CHECKING:",
    "@abstractmethod",
    "pass",
    "raise ImportError",
    "raise ValueError",
    "except ImportError:",
]

[tool.coverage.paths]
source = ["src"]
