{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f823f6",
   "metadata": {},
   "source": [
    "# LeRobot Policy Integration with PhysicalAI\n",
    "\n",
    "This notebook demonstrates how PhysicalAI integrates with [LeRobot](https://github.com/huggingface/lerobot) policies for end-to-end robot learning workflows. You'll learn:\n",
    "\n",
    "1. **LeRobotPolicy Wrapper** - Universal wrapper that works with any LeRobot policy\n",
    "2. **Explicit Policy Wrappers** - Type-safe wrappers for specific policies (ACT, Diffusion, Groot etc.)\n",
    "3. **Training Workflow** - End-to-end training with the `Trainer` class\n",
    "4. **Inference** - Running trained policies for robot control\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- PhysicalAI library installed (`pip install -e library/`)\n",
    "- LeRobot installed (`pip install lerobot`)\n",
    "- A dataset (we'll use HuggingFace datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca20b3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e62ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "\n",
    "# PhysicalAI policy wrappers\n",
    "from physicalai.policies.lerobot import (\n",
    "    LeRobotPolicy,  # Universal wrapper for any LeRobot policy\n",
    "    ACT,  # Explicit ACT policy wrapper\n",
    "    Diffusion,  # Explicit Diffusion policy wrapper\n",
    "    Groot,  # Explicit Groot (GR00T-N1) policy wrapper\n",
    ")\n",
    "\n",
    "# Data and training utilities\n",
    "from physicalai.data.lerobot import LeRobotDataModule, get_delta_timestamps_from_policy\n",
    "from physicalai.train import Trainer\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df93a4",
   "metadata": {},
   "source": [
    "## 2. Understanding LeRobotPolicy Wrapper\n",
    "\n",
    "The `LeRobotPolicy` is a universal wrapper that can load **any** LeRobot policy by name. It provides:\n",
    "\n",
    "- **Automatic configuration loading** from LeRobot's policy registry\n",
    "- **PyTorch Lightning integration** for seamless training\n",
    "- **Unified interface** across all policy types\n",
    "\n",
    "### Available Policies\n",
    "\n",
    "LeRobot supports several policy architectures. PhysicalAI provides **explicit wrappers** for:\n",
    "- **ACT (Action Chunking Transformer)** - Predicts action sequences using transformers with a VAE\n",
    "- **Diffusion Policy** - Uses denoising diffusion for action generation\n",
    "- **Groot (GR00T-N1)** - NVIDIA's vision-language-action foundation model for humanoid robots\n",
    "\n",
    "For other policies (VQ-BeT, TDMPC, Pi0, etc.), use the universal `LeRobotPolicy` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69085029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy type: <class 'physicalai.policies.lerobot.universal.LeRobotPolicy'>\n",
      "Policy name: act\n",
      "\n",
      "Eager initialized policy config (first 10 keys):\n",
      "  n_obs_steps: 1\n",
      "  input_features: {'observation.image': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 96, 96)), 'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(2,))}\n",
      "  output_features: {'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(2,))}\n",
      "  device: cuda\n",
      "  use_amp: False\n",
      "  push_to_hub: True\n",
      "  repo_id: None\n",
      "  private: None\n",
      "  tags: None\n",
      "  license: None\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "# Create a LeRobotPolicy using the universal wrapper\n",
    "# Just specify the policy name - configuration is loaded automatically\n",
    "\n",
    "act_policy = LeRobotPolicy(policy_name=\"act\")\n",
    "print(f\"Policy type: {type(act_policy)}\")\n",
    "print(f\"Policy name: {act_policy.policy_name}\")\n",
    "\n",
    "# Note: The underlying LeRobot policy is created during setup() when features\n",
    "# are available from the DataModule. For immediate initialization, use from_dataset():\n",
    "act_policy_eager = LeRobotPolicy.from_dataset(\"act\", \"lerobot/pusht\")\n",
    "print(f\"\\nEager initialized policy config (first 10 keys):\")\n",
    "for i, (k, v) in enumerate(vars(act_policy_eager._config).items()):\n",
    "    if i >= 10:\n",
    "        print(\"  ...\")\n",
    "        break\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0bea5",
   "metadata": {},
   "source": [
    "## 3. Explicit Policy Wrappers\n",
    "\n",
    "For type-safety and IDE autocompletion, PhysicalAI provides **explicit wrappers** for specific policy types:\n",
    "- `ACT` - Action Chunking Transformer\n",
    "- `Diffusion` - Diffusion Policy  \n",
    "- `Groot` - NVIDIA's GR00T-N1 Foundation Model\n",
    "\n",
    "These wrappers expose policy-specific parameters directly as constructor arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0742be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT Policy created with 100-step action chunks\n",
      "  - chunk_size: 100\n",
      "  - n_obs_steps: 1\n"
     ]
    }
   ],
   "source": [
    "# ACT Policy - Action Chunking Transformer\n",
    "# Predicts sequences of actions using a transformer with VAE latent space\n",
    "\n",
    "act = ACT(\n",
    "    chunk_size=100,  # Number of future actions to predict (action chunking)\n",
    "    n_obs_steps=1,  # Number of observation history steps (1 = current only)\n",
    "    dim_model=256,  # Transformer hidden dimension\n",
    "    n_heads=8,  # Number of attention heads\n",
    "    n_encoder_layers=4,\n",
    "    n_decoder_layers=1,\n",
    "    optimizer_lr=1e-5,\n",
    ")\n",
    "print(\"ACT Policy created with 100-step action chunks\")\n",
    "print(f\"  - chunk_size: {act._policy_config['chunk_size']}\")\n",
    "print(f\"  - n_obs_steps: {act._policy_config['n_obs_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a142ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion Policy created\n",
      "  - horizon: 16\n",
      "  - n_obs_steps: 2\n"
     ]
    }
   ],
   "source": [
    "# Diffusion Policy - Denoising Diffusion for Action Generation\n",
    "# Uses iterative denoising to generate smooth action trajectories\n",
    "\n",
    "diffusion = Diffusion(\n",
    "    n_action_steps=8,  # Actions to execute per inference\n",
    "    horizon=16,  # Total planning horizon\n",
    "    n_obs_steps=2,  # Observation history length\n",
    "    num_inference_steps=10,  # Denoising steps during inference\n",
    "    optimizer_lr=1e-4,\n",
    ")\n",
    "print(\"Diffusion Policy created\")\n",
    "print(f\"  - horizon: {diffusion._policy_config['horizon']}\")\n",
    "print(f\"  - n_obs_steps: {diffusion._policy_config['n_obs_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groot Policy created\n",
      "  - chunk_size: 50\n",
      "  - tune_projector: True\n"
     ]
    }
   ],
   "source": [
    "# Groot Policy - NVIDIA's GR00T-N1.5 Foundation Model\n",
    "# Vision-language-action model for generalist humanoid robots\n",
    "# Note: Requires 24GB+ VRAM and `pip install physicalai[groot]`\n",
    "\n",
    "groot = Groot(\n",
    "    chunk_size=50,  # Action sequence length\n",
    "    n_action_steps=50,  # Actions to execute per inference\n",
    "    tune_projector=True,  # Fine-tune vision-to-LLM projector\n",
    "    tune_diffusion_model=True,  # Fine-tune diffusion action head\n",
    "    tune_llm=False,  # Keep LLM frozen (saves memory)\n",
    "    optimizer_lr=1e-4,\n",
    ")\n",
    "print(\"Groot Policy created\")\n",
    "print(f\"  - chunk_size: {groot._policy_config['chunk_size']}\")\n",
    "print(f\"  - tune_projector: {groot._policy_config['tune_projector']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f00f3",
   "metadata": {},
   "source": [
    "## 4. Delta Timestamps: Handling Action Chunking\n",
    "\n",
    "Policies like ACT predict multiple future actions (action chunking). The `delta_timestamps` parameter tells the dataset how to align actions across time steps.\n",
    "\n",
    "**Key concept**: If ACT predicts 100 future actions at 10 FPS, it needs actions spanning 10 seconds (100 * 0.1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77f3618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n",
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT delta_timestamps:\n",
      "  action: 100 values\n",
      "  First 5: [0.0, 0.1, 0.2, 0.3, 0.4]\n",
      "  Last 5: [9.5, 9.6, 9.7, 9.8, 9.9]\n",
      "\n",
      "Diffusion delta_timestamps:\n",
      "  observation.images.top: [-0.1, 0.0]\n",
      "  observation.state: [-0.1, 0.0]\n",
      "  action: [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4]\n"
     ]
    }
   ],
   "source": [
    "# Generate delta timestamps automatically from policy configuration\n",
    "fps = 10  # Dataset recording frequency\n",
    "\n",
    "# For ACT with chunk_size=100\n",
    "act_delta_timestamps = get_delta_timestamps_from_policy(\"act\", fps=fps)\n",
    "print(\"ACT delta_timestamps:\")\n",
    "print(f\"  action: {len(act_delta_timestamps['action'])} values\")\n",
    "print(f\"  First 5: {act_delta_timestamps['action'][:5]}\")\n",
    "print(f\"  Last 5: {act_delta_timestamps['action'][-5:]}\")\n",
    "\n",
    "# For Diffusion with n_obs_steps=2 and horizon=16\n",
    "diffusion_delta_timestamps = get_delta_timestamps_from_policy(\"diffusion\", fps=fps)\n",
    "print(\"\\nDiffusion delta_timestamps:\")\n",
    "for key, values in diffusion_delta_timestamps.items():\n",
    "    print(f\"  {key}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26a290",
   "metadata": {},
   "source": [
    "## 5. Setting Up the DataModule\n",
    "\n",
    "The `LeRobotDataModule` handles data loading and preprocessing. It supports two data formats:\n",
    "\n",
    "- **`\"physicalai\"`** - Uses the `Observation` dataclass (recommended for PhysicalAI workflows)\n",
    "- **`\"lerobot\"`** - Native LeRobot dictionary format (for compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab92e9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataModule created:\n",
      "  - train_batch_size: 8\n",
      "  - data_format: physicalai\n"
     ]
    }
   ],
   "source": [
    "# Create the DataModule with a HuggingFace dataset\n",
    "# Using lerobot/pusht as an example dataset\n",
    "\n",
    "fps = 10  # Recording frequency of the dataset\n",
    "\n",
    "# Note: video_backend=\"pyav\" for better compatibility with various video codecs\n",
    "datamodule = LeRobotDataModule(\n",
    "    repo_id=\"lerobot/pusht\",  # HuggingFace dataset\n",
    "    train_batch_size=8,\n",
    "    data_format=\"physicalai\",  # Use Observation dataclass\n",
    "    delta_timestamps=get_delta_timestamps_from_policy(\"act\", fps=fps),\n",
    "    video_backend=\"pyav\",  # Use pyav for video decoding\n",
    ")\n",
    "\n",
    "print(f\"DataModule created:\")\n",
    "print(f\"  - train_batch_size: {datamodule.train_batch_size}\")\n",
    "print(f\"  - data_format: {datamodule.data_format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f7e701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 25650 samples\n",
      "\n",
      "Sample type: Observation\n",
      "State shape: torch.Size([2])\n",
      "Action shape: torch.Size([100, 2])\n",
      "Images shape: torch.Size([3, 96, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset structure\n",
    "datamodule.setup(\"fit\")\n",
    "dataset = datamodule.train_dataset\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "\n",
    "# Get a sample - the physicalai format returns Observation dataclass\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample type: {type(sample).__name__}\")\n",
    "print(f\"State shape: {sample.state.shape}\")\n",
    "print(f\"Action shape: {sample.action.shape}\")\n",
    "if isinstance(sample.images, dict):\n",
    "    for name, img in sample.images.items():\n",
    "        print(f\"Image '{name}' shape: {img.shape}\")\n",
    "else:\n",
    "    print(f\"Images shape: {sample.images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278d2f6",
   "metadata": {},
   "source": [
    "## 6. End-to-End Training with Trainer\n",
    "\n",
    "The `Trainer` class is a PyTorch Lightning-based trainer that handles:\n",
    "\n",
    "- Policy initialization based on dataset features\n",
    "- Automatic callback injection (e.g., `PolicyDatasetInteraction`)\n",
    "- Logging, checkpointing, and distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffd369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer and Policy ready for training!\n",
      "  - max_steps: 5\n"
     ]
    }
   ],
   "source": [
    "# Create the policy for training\n",
    "policy = ACT(\n",
    "    chunk_size=100,\n",
    "    n_obs_steps=1,\n",
    "    optimizer_lr=1e-5,\n",
    ")\n",
    "\n",
    "# Create the trainer\n",
    "trainer = Trainer(\n",
    "    max_steps=5,  # Just 5 steps for demo\n",
    "    accelerator=\"auto\",  # Automatically select GPU/CPU\n",
    "    enable_checkpointing=False,  # Disable for demo\n",
    "    logger=False,  # Disable logging for demo\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "print(\"Trainer and Policy ready for training!\")\n",
    "print(f\"  - max_steps: {trainer.max_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8426b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n",
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type      | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------\n",
      "0 | val_rollout     | Rollout   | 0      | train | 0    \n",
      "1 | test_rollout    | Rollout   | 0      | train | 0    \n",
      "2 | _lerobot_policy | ACTPolicy | 51.6 M | train | 0    \n",
      "--------------------------------------------------------------\n",
      "51.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.6 M    Total params\n",
      "206.356   Total estimated model params size (MB)\n",
      "184       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "\n",
      "  | Name            | Type      | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------\n",
      "0 | val_rollout     | Rollout   | 0      | train | 0    \n",
      "1 | test_rollout    | Rollout   | 0      | train | 0    \n",
      "2 | _lerobot_policy | ACTPolicy | 51.6 M | train | 0    \n",
      "--------------------------------------------------------------\n",
      "51.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.6 M    Total params\n",
      "206.356   Total estimated model params size (MB)\n",
      "184       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakcay/projects/geti/geti-action/library/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:378: You have overridden `transfer_batch_to_device` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s, train/loss=25.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s, train/loss=25.10]\n",
      "\n",
      "\n",
      "✅ Training complete!\n",
      "\n",
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Start training!\n",
    "# The Trainer automatically:\n",
    "# 1. Calls policy.setup() with dataset features\n",
    "# 2. Injects PolicyDatasetInteraction callback\n",
    "# 3. Handles training loop\n",
    "\n",
    "trainer.fit(model=policy, datamodule=datamodule)\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bd63f",
   "metadata": {},
   "source": [
    "## 7. Running Inference\n",
    "\n",
    "After training, use the policy for inference to predict actions from observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dda030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy device: cuda\n",
      "\n",
      "Input state shape (before preprocessing): torch.Size([2])\n",
      "Input images shape (before preprocessing): torch.Size([3, 96, 96])\n",
      "Predicted action shape: torch.Size([1, 2])\n",
      "\n",
      "Predicted action:\n",
      "tensor([[197.6160, 250.0277]])\n"
     ]
    }
   ],
   "source": [
    "# Set policy to evaluation mode and move to device\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the best available device (XPU > CUDA > CPU).\"\"\"\n",
    "    if hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "        return torch.device(\"xpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "policy = policy.to(device)\n",
    "policy.eval()\n",
    "\n",
    "print(f\"Policy device: {device}\")\n",
    "\n",
    "# Get a sample observation from the dataset (unbatched, single sample)\n",
    "sample = dataset[0]\n",
    "\n",
    "# Create observation for inference\n",
    "# NOTE: The LeRobot preprocessor pipeline automatically handles:\n",
    "#   1. AddBatchDimensionProcessorStep - adds batch dim to unbatched inputs\n",
    "#   2. DeviceProcessorStep - moves tensors to the policy's device\n",
    "#   3. NormalizerProcessorStep - normalizes inputs using dataset statistics\n",
    "# So we pass raw unbatched data - no need for manual .unsqueeze(0) or .to(device)\n",
    "from physicalai.data.observation import Observation\n",
    "\n",
    "observation = Observation(\n",
    "    state=sample.state,  # Shape: [2] -> preprocessor adds batch -> [1, 2]\n",
    "    images=sample.images,  # Shape: [C, H, W] -> preprocessor adds batch -> [1, C, H, W]\n",
    "    action=None,\n",
    ")\n",
    "\n",
    "# Run inference using select_action (which applies the preprocessor pipeline)\n",
    "with torch.no_grad():\n",
    "    action = policy.select_action(observation)\n",
    "\n",
    "print(f\"\\nInput state shape (before preprocessing): {sample.state.shape}\")\n",
    "print(f\"Input images shape (before preprocessing): {sample.images.shape}\")\n",
    "print(f\"Predicted action shape: {action.shape}\")\n",
    "print(f\"\\nPredicted action:\\n{action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf34279",
   "metadata": {},
   "source": [
    "## 8. Comparing Wrapper Approaches\n",
    "\n",
    "| Approach | Pros | Cons |\n",
    "|----------|------|------|\n",
    "| **Universal `LeRobotPolicy`** | Works with any LeRobot policy by name | No IDE autocompletion for policy-specific params |\n",
    "| | Good for dynamic policy selection | |\n",
    "| **Explicit Wrappers (`ACT`, `Diffusion`, `Groot`)** | Type-safe with IDE autocompletion | Need to import specific class |\n",
    "| | Policy-specific parameters as constructor args | |\n",
    "| | Better for production code | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43bf4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both approaches create equivalent policies:\n",
      "  universal_act.policy_name = 'act'\n",
      "  explicit_act.policy_name = 'act'\n"
     ]
    }
   ],
   "source": [
    "# Universal wrapper - flexible, works with any policy\n",
    "universal_act = LeRobotPolicy(policy_name=\"act\")\n",
    "universal_diffusion = LeRobotPolicy(policy_name=\"diffusion\")\n",
    "\n",
    "# Explicit wrappers - type-safe, IDE autocompletion\n",
    "explicit_act = ACT(chunk_size=100)\n",
    "explicit_diffusion = Diffusion(horizon=16)\n",
    "# explicit_groot = Groot(chunk_size=50)  # Requires GPU with 24GB+ VRAM\n",
    "\n",
    "print(\"Both approaches create equivalent policies:\")\n",
    "print(f\"  universal_act.policy_name = '{universal_act.policy_name}'\")\n",
    "print(f\"  explicit_act.policy_name = '{explicit_act.policy_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e72245",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **LeRobotPolicy** - Universal wrapper for any LeRobot policy\n",
    "2. **Explicit Wrappers** - Type-safe `ACT`, `Diffusion`, `Groot`\n",
    "3. **Delta Timestamps** - Automatic generation via `get_delta_timestamps_from_policy()`\n",
    "4. **LeRobotDataModule** - Data loading with \"physicalai\" or \"lerobot\" format\n",
    "5. **Trainer** - PyTorch Lightning-based training with automatic policy setup\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore different policies for your task\n",
    "- Use image observations with the `images` field in `Observation`\n",
    "- Try distributed training with `Trainer(devices=2, strategy=\"ddp\")`\n",
    "- Export trained policies for deployment\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LeRobot Documentation](https://github.com/huggingface/lerobot)\n",
    "- [PhysicalAI Library](../../README.md)\n",
    "- [Policy Design Document](../../docs/design/policies.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "library",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
