# ACT Policy Training Configuration
# Train Action Chunking Transformer using LeRobot's implementation
#
# Usage:
#   getiaction fit --config configs/lerobot_act.yaml
#
# Override parameters:
#   getiaction fit --config configs/lerobot_act.yaml --model.init_args.dim_model 1024

model:
  class_path: getiaction.policies.lerobot.ACT
  init_args:
    # Core architecture - MUST match delta_timestamps length
    dim_model: 512
    chunk_size: 10 # Must match length of action delta_timestamps
    n_action_steps: 10 # Must match length of action delta_timestamps

    # Vision backbone
    vision_backbone: "resnet18" # Options: resnet18, resnet34, resnet50
    pretrained_backbone_weights: "ResNet18_Weights.IMAGENET1K_V1"
    optimizer_lr_backbone: 1.0e-5 # Separate learning rate for backbone

    # VAE configuration
    use_vae: true # Use VAE for action distribution modeling
    latent_dim: 32
    kl_weight: 10.0 # Weight for KL divergence loss

    # Transformer architecture
    n_encoder_layers: 4
    n_decoder_layers: 1
    n_heads: 8
    dim_feedforward: 3200
    dropout: 0.1

    # Optimization
    learning_rate: 1.0e-5

    # Temporal ensembling (optional, set to null to disable)
    temporal_ensemble_coeff: null # e.g., 0.01 for ensembling

data:
  class_path: getiaction.data.lerobot.LeRobotDataModule
  init_args:
    repo_id: "lerobot/aloha_sim_transfer_cube_human"
    train_batch_size: 8
    data_format: "lerobot" # Output format: "lerobot" (flattened dict) or "getiaction" (Observation)
    delta_timestamps:
      action: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

trainer:
  max_epochs: 100
  accelerator: gpu
  devices: 1
  precision: 32
  log_every_n_steps: 10
  check_val_every_n_epoch: 1
