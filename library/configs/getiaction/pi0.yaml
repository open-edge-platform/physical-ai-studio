# Pi0 Policy Training Configuration
#
# Usage:
#   getiaction fit --config configs/getiaction/pi0.yaml

model:
  class_path: getiaction.policies.Pi0
  init_args:
    # Model variant
    variant: pi0
    paligemma_variant: gemma_2b
    action_expert_variant: gemma_300m
    dtype: bfloat16

    # Input / output structure
    n_obs_steps: 1
    chunk_size: 50
    n_action_steps: 50
    max_state_dim: 32
    max_action_dim: 32

    # Image preprocessing
    image_resolution:
      - 224
      - 224

    # Flow matching parameters
    num_inference_steps: 10

    # Finetuning settings - tune action expert by default
    tune_paligemma: false
    tune_action_expert: true
    tune_vision_encoder: false

    # Training presets
    learning_rate: 2.5e-5
    weight_decay: 1e-10
    warmup_steps: 1000
    decay_steps: 30000
    decay_lr: 2.5e-6
    grad_clip_norm: 1.0

data:
  class_path: getiaction.data.lerobot.LeRobotDataModule
  init_args:
    repo_id: "lerobot/aloha_sim_transfer_cube_human"
    train_batch_size: 8
    data_format: "getiaction"

trainer:
  max_epochs: 100
  accelerator: gpu
  devices: 1
  precision: 32
  log_every_n_steps: 100
  check_val_every_n_epoch: 10
