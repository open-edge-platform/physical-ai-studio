# Example: Training config using dataclass/Pydantic pattern
# This uses the traditional from_config approach

seed_everything: 42

trainer:
  max_epochs: 100
  accelerator: auto
  devices: 1
  log_every_n_steps: 10
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: train/loss
        mode: min
        save_top_k: 3
        filename: "dummy-{epoch:02d}-{train/loss:.2f}"

model:
  class_path: getiaction.policies.dummy.policy.Dummy
  init_args:
    model:
      class_path: getiaction.policies.dummy.model.Dummy
      init_args:
        action_shape: [7]
        n_action_steps: 4
        temporal_ensemble_coeff: 0.1
        n_obs_steps: 2
        horizon: 8
    optimizer:
      class_path: torch.optim.Adam
      init_args:
        lr: 0.001
        weight_decay: 0.00001
        betas: [0.9, 0.999]

data:
  class_path: getiaction.data.lerobot.LeRobotDataModule
  init_args:
    repo_id: "lerobot/pusht"
    train_batch_size: 32


