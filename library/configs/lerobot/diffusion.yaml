# LeRobot Diffusion Policy Configuration
# Train Diffusion Policy using LeRobot's implementation
#
# Usage:
#   getiaction fit --config configs/lerobot/diffusion.yaml
#
# Override parameters:
#   getiaction fit --config configs/lerobot/diffusion.yaml --model.horizon 32

model:
  class_path: getiaction.policies.lerobot.Diffusion
  init_args:
    # Core architecture - horizon must match len(delta_timestamps["action"])
    n_obs_steps: 2
    horizon: 16
    n_action_steps: 8
    drop_n_last_frames: 7

    # Vision backbone
    vision_backbone: "resnet18"
    crop_shape: [84, 84]
    crop_is_random: true
    use_group_norm: true
    spatial_softmax_num_keypoints: 32

    # U-Net architecture
    down_dims: [512, 1024, 2048]
    kernel_size: 5
    n_groups: 8
    diffusion_step_embed_dim: 128
    use_film_scale_modulation: true

    # Noise scheduler
    noise_scheduler_type: "DDPM"
    num_train_timesteps: 100
    beta_schedule: "squaredcos_cap_v2"
    prediction_type: "epsilon"

    # Optimization
    optimizer_lr: 1.0e-4
    optimizer_weight_decay: 1.0e-6
    scheduler_name: "cosine"
    scheduler_warmup_steps: 500

data:
  class_path: getiaction.data.lerobot.LeRobotDataModule
  init_args:
    repo_id: "lerobot/aloha_sim_transfer_cube_human"
    train_batch_size: 8
    data_format: "lerobot" # Output format: "lerobot" (flattened dict) or "getiaction" (Observation)
    delta_timestamps:
      # Observation timestamps for n_obs_steps=2: [-0.1, 0.0]
      observation.images.top: [-0.1, 0.0]
      observation.state: [-0.1, 0.0]
      # Action timestamps: horizon=16 starting from -0.1
      action:
        [
          -0.1,
          0.0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          1.0,
          1.1,
          1.2,
          1.3,
          1.4,
        ]

trainer:
  max_epochs: 100
  precision: 16-mixed
  log_every_n_steps: 10
