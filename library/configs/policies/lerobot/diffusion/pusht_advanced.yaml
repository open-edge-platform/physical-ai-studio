# Diffusion Policy - Advanced Configuration
# Complete reference showing all configurable parameters
#
# Usage:
#   getiaction fit --config configs/policies/lerobot/diffusion/pusht_advanced.yaml
#
# This config demonstrates every parameter with detailed explanations

model:
  class_path: getiaction.policies.lerobot.diffusion.Diffusion
  init_args:
    # === Temporal Configuration ===
    n_obs_steps: 2 # Number of observation frames to condition on
    horizon: 16 # Prediction horizon (MUST match len(delta_timestamps["action"]))
    n_action_steps: 8 # Number of action steps to execute from predicted trajectory
    drop_n_last_frames: 0 # Drop last N frames from observations (for temporal alignment)

    # === Vision Backbone Configuration ===
    vision_backbone: resnet18 # Vision encoder: resnet18, resnet34, resnet50
    crop_shape: [84, 84] # Crop size for input images [height, width]
    crop_is_random: true # Use random crops (true) or center crop (false)
    pretrained_backbone_weights: ResNet18_Weights.IMAGENET1K_V1 # Pretrained weights
    use_group_norm: true # Replace BatchNorm with GroupNorm in backbone
    spatial_softmax_num_keypoints: 32 # Number of keypoints for spatial softmax
    use_separate_rgb_encoder_per_camera: false # Separate encoders per camera

    # === U-Net Architecture ===
    down_dims: [512, 1024, 2048] # Downsampling dimensions in U-Net
    kernel_size: 5 # Convolutional kernel size in U-Net
    n_groups: 8 # Number of groups for GroupNorm layers
    diffusion_step_embed_dim: 128 # Embedding dimension for diffusion timestep
    use_film_scale_modulation: true # Use FiLM (Feature-wise Linear Modulation) for conditioning

    # === Diffusion Process Configuration ===
    noise_scheduler_type: DDPM # Scheduler type: DDPM, DDIM
    num_train_timesteps: 100 # Number of diffusion steps during training
    beta_schedule: squaredcos_cap_v2 # Noise schedule: linear, squaredcos_cap_v2
    beta_start: 0.0001 # Starting beta value for noise schedule
    beta_end: 0.02 # Ending beta value for noise schedule
    prediction_type: epsilon # Prediction target: epsilon, sample, v_prediction
    clip_sample: true # Clip predicted samples to [-1, 1]
    clip_sample_range: 1.0 # Range for clipping samples
    num_inference_steps: 10 # Denoising steps at inference (null = use num_train_timesteps)

    # === Loss Configuration ===
    do_mask_loss_for_padding: false # Mask loss for padded timesteps

    # === Optimization Configuration ===
    learning_rate: 1.0e-4 # Base learning rate for Adam optimizer
    optimizer_betas: [0.95, 0.999] # Adam beta parameters [beta1, beta2]
    optimizer_eps: 1.0e-8 # Adam epsilon for numerical stability
    optimizer_weight_decay: 1.0e-6 # Weight decay for L2 regularization
    scheduler_name: cosine # LR scheduler: cosine, constant, linear
    scheduler_warmup_steps: 500 # Number of warmup steps for learning rate


data:
  class_path: getiaction.data.lerobot.LeRobotDataModule
  init_args:
    repo_id: lerobot/pusht # HuggingFace dataset repository
    train_batch_size: 64 # Batch size for training
    data_format: lerobot # Use LeRobot's native data format

    # Delta timestamps for temporal alignment
    # Action must have 16 timesteps to match horizon=16
    delta_timestamps:
      action: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]

trainer:
  max_epochs: 3000
  accelerator: gpu
  devices: 1
  log_every_n_steps: 100
