"""Add dataset_id to environment

Revision ID: aa0f562acb23
Revises: 35da80a6d570
Create Date: 2026-02-17 07:52:49.802980

"""

from collections.abc import Sequence

import sqlalchemy as sa

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "aa0f562acb23"
down_revision: str | Sequence[str] | None = "35da80a6d570"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    conn = op.get_bind()
    conn.execute(sa.text("PRAGMA foreign_keys = OFF;"))  # quickly ignore foreign keys when migrating the datasets
    conn.execute(sa.text("DROP TABLE IF EXISTS datasets_tmp;"))

    op.create_table(
        "datasets_tmp",
        sa.Column("id", sa.Text(), nullable=False),
        sa.Column("project_id", sa.Text(), nullable=False),
        sa.Column("environment_id", sa.Text(), nullable=False),
        sa.Column("name", sa.String(length=255), nullable=False),
        sa.Column("path", sa.String(length=255), nullable=False),
        sa.Column("created_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.Column("updated_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.PrimaryKeyConstraint("id"),
        sa.ForeignKeyConstraint(["project_id"], ["projects.id"], ondelete="CASCADE"),
        sa.ForeignKeyConstraint(["environment_id"], ["project_environments.id"]),
    )
    insert_sql = """
        INSERT INTO datasets_tmp (
            project_id,
            environment_id,
            id,
            name,
            path,
            created_at,
            updated_at
        )
        SELECT
            d.project_id,
            (
                SELECT e.id
                FROM project_environments e
                WHERE e.project_id = d.project_id
                LIMIT 1
            ) as environment_id,
            d.id,
            d.name,
            d.path,
            d.created_at,
            d.updated_at
        FROM datasets d
    """

    conn.execute(sa.text(insert_sql))
    op.drop_table("datasets")
    op.rename_table("datasets_tmp", "datasets")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    with op.batch_alter_table("datasets", schema=None) as batch_op:
        batch_op.drop_column("environment_id")

    # ### end Alembic commands ###
